---
title: "ClimateChange"
author: "Sylvia Liu"
date: "28/04/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(dplyr)
library(readxl)
library(tibble)
library(ggplot2)
library(ggthemes)
library(maps)

library(plotly) # Interactive data visualizations
library(viridis) # Color gradients
library(lubridate)

library(randomForest) 
library(ranger)       # a faster implementation of randomForest
library(caret)        # performe many machine learning models
library(broom)  # try: `install.packages("backports")` if diretly installing broom gives an error

library(reshape2) # to use melt()

library(deSolve)
library(permimp) # for calculating conditional importance in a speedy way
```

## Reading data
```{r}
covid_data <- read.csv("owid-covid-data.csv")
covid_data$date <- as.Date(covid_data$date) #, format = "%d/%m/%y")
covid <- covid_data
#head(covid_data)
```


## Vaccinations progress  

### Vaccine Roll-Out Index (vri) values for the countries

(Reference: https://www.mdpi.com/2076-393X/10/2/194/htm)

> **Estimate Vaccine Uptakes Rates r* for Countries**
"The logistic growth model was used to estimate the vaccination uptake rate. In the logistic model, the cumulative number of doses administered c(t) satisfies the following equation: $$c(t) = \frac{K}{1+a\cdot{e}^{-r\cdot t}}$$,"_ where K is the total vaccinations administered at the end of the date recorded, r is the vaccination uptake rate(i.e. speed), and $\frac{K}{1+a} = c(0)$ is the initial number of doses given.


```{r}
estimate_r <- function(data){

  data$index <- c(1:length(data$total_vaccinations))

  SS <- getInitial(data$total_vaccinations ~ SSlogis(data$index, alpha, xmid, scale), data = data)

  K_start <- SS["alpha"]
  R_start <- 1/SS["scale"]
  N0_start <- SS["alpha"]/(exp(SS["xmid"]/SS["scale"])+1)
  
  log_formula <- formula(data$total_vaccinations ~ K*N0*exp(R*data$index)/(K + N0*(exp(R*data$index) - 1)))
  
  
  formu<-nls(log_formula, data = data, start = list(K = K_start, R = R_start, N0 = N0_start))
  
  return(formu)
}
```


> Define and Calculate Vaccine Roll-Out Index (vri) 
"The Vaccine Roll-out Index (vri) for a country was defined as follows: $$vri=r\cdot \frac{d}{N}$$," where r is the vaccination uptake rate as defined in the previous section, d is the total vaccinations, and N is the population. 

**vri was used as an index to compare the overall vaccination progression among different countries, as it reflects both the speed and the density/extend.**

```{r}
## calculate vri using: est_rate * d/N
estimate_vri <- function(data, r){
  vri <- r * (data$total_vaccinations[length(data$total_vaccinations)]) / data$population[1]
  
  return(vri)
}
```


```{r}
## FOR measuring goodness of fit
RSQUARE = function(y_actual,y_predict){
  cor(y_actual,y_predict)^2
}
```


```{r}
countries <- unique(covid$location)


## Run the following code to generate the vri dataset for valid countries
vri_data <- NULL
avg <- 0
count <- 0

for (c in countries) {

  ## Not enough data for initialization coefficients
  if (c %in% c("Afghanistan", "Antigua and Barbuda", "Bhutan", "Bonaire Sint Eustatius and Saba", "Botswana", "Cameroon", "Cote d'Ivoire", "Democratic Republic of Congo", "Ethiopia", "Eritrea", "Gabon", "Ghana", "Guernsey", "Guinea", "Kenya", "Kuwait", "Liberia", "Marshall Islands", "Micronesia (country)", "Namibia", "Nepal", "Niger", "Nigeria", "Palau", "Palestine", "Philippines", "Pitcairn", "Puerto Rico", "Rwanda", "Saint Helena", "Saint Pierre and Miquelon", "Senegal", "Somalia", "South Sudan", "Sudan", "Tokelau", "Turkmenistan", "Uganda", "Vatican", "World", "Zambia", "International")) {
    next
  }
  country <- covid[covid$location == c, ] %>%
  filter(!is.na(people_vaccinated) & people_vaccinated != 0) %>%
  filter(!is.na(total_vaccinations) & total_vaccinations != 0) %>%
  select(location, date, people_vaccinated, total_vaccinations, population)
  
  formu <- estimate_r(country)
  
  ## Goodness of fit
  #avg <- avg +  RSQUARE(country$people_vaccinated, predict(formu))
  #count <- count + 1
  
  r <- summary(formu)$coefficients[[2]]
  
  vri <- estimate_vri(country, r)
  
  
  temp <- data.frame(location = c, vri = vri, 
                     aged_65_older = covid[covid$location == c, ]$aged_65_older[1], 
                     gdp_per_capita = covid[covid$location == c, ]$gdp_per_capita[1], 
                     cardiovasc_death_rate = covid[covid$location == c, ]$cardiovasc_death_rate[1], 
                     population_density = covid[covid$location == c, ]$population_density[1], 
                     hospital_beds_per_thousand = covid[covid$location == c, ]$hospital_beds_per_thousand[1], 
                     human_development_index = covid[covid$location == c, ]$human_development_index[1],
                     extreme_poverty = covid[covid$location == c, ]$extreme_poverty[1],
                     diabetes_prevalence = covid[covid$location == c, ]$diabetes_prevalence[1],
                     life_expectancy = covid[covid$location == c, ]$life_expectancy[1],
                     iso_code = covid[covid$location == c, ]$iso_code[1])
                     
  


  vri_data <- rbind(vri_data, temp)
}


# Goodness of fit example:
#avg / count
```

Output the vri_data to a csv file
```{r}
#write.csv(vri_data, "~/Downloads/DATA3888/2022S1/group_assignment/vaccine/vri_data.csv", row.names = FALSE)
vri_data <- read_csv("vri_data.csv")
```


**Evaluation of the metric on est.r**
```{r}
## Step2: Another function for evaluating the logistic model we created for the estimate r (r*), 
## including fitted plots, godness of fit values


# Example:


```


### The association between vaccination uptake rate and social-economic factors

#### Merging datasets

**I have comment out the government trust dataset as it only contains OECD countries**

Merge joint covid data with vri.

```{r}
corruption <- read_xlsx("CPI2020_GlobalTablesTS_210125.xlsx", sheet=1,skip=2)
corruption <- corruption %>% select (c("ISO3", "CPI score 2020")) 
#corruption

happiness <- read_csv("happiness-cantril-ladder.csv")
happiness <- happiness %>% group_by(Code) %>%
  arrange(Year) %>%
  filter(!is.na(`Life satisfaction in Cantril Ladder (World Happiness Report 2021)`)) %>%
  dplyr::summarise(satisfaction=last(`Life satisfaction in Cantril Ladder (World Happiness Report 2021)`)) 


joint_data <- merge(vri_data,corruption,  by.x=c("iso_code"), by.y=c("ISO3"))

joint_data <- merge(joint_data,happiness, by.x=c("iso_code"), by.y=c("Code"))

# GHE-INDEX
ghs <- read_csv("2021-GHS-Index-April-2022.csv")
ghs <- ghs %>% filter(Year == 2021) %>% select(Country,`OVERALL SCORE`)

joint_data <- merge(joint_data, ghs,  by.x=c("location"), by.y=c("Country"))
colnames(joint_data)[15] <- "GHS_score"
joint_data
```


#### Selecting Covariates

```{r}
# Basic scatter plot
df <- joint_data %>% filter( (vri < 0.08) & !is.na(population_density) # set a threshold to remove outliers:
                                    &!is.na(gdp_per_capita) &!is.na(aged_65_older)&
                                      !is.na(extreme_poverty)&
                                      !is.na(human_development_index)& 
                                      !is.na(cardiovasc_death_rate)& 
                                      !is.na(diabetes_prevalence)&
                                      !is.na(hospital_beds_per_thousand)) %>% 
                                      
                            select(c(location,vri,population_density,gdp_per_capita,aged_65_older,
                                     `CPI score 2020`,
                                     satisfaction,extreme_poverty,human_development_index,life_expectancy,
                                      cardiovasc_death_rate,diabetes_prevalence,
                                      hospital_beds_per_thousand, GHS_score)) 

df
```

##### Demographic factors (scatter plots)
Variables: `population_density`, age(`aged_65_older`/`aged_70_older`), `gdp_per_capita`, 
```{r}
ggplot(df, aes(x=vri, y=population_density)) + geom_point() + ggtitle("Population density vs Vaccine Roll-out Index(vri)") + ylim(c(0,500))
ggplot(df, aes(x=vri, y=gdp_per_capita)) + geom_point() + ggtitle("GDP per capita vs Vaccine Roll-out Index(vri)")
ggplot(df, aes(x=vri, y=aged_65_older)) + geom_point() + ggtitle("Aged over 65 vs Vaccine Roll-out Index(vri)")
```

##### Social and Economic
Variables: Stringency(`stringency_index`), trust(`share_who _trust_government`), corruption(`CPI score 2020`), happiness(`satisfaction`), `extreme_poverty`, `human_development_index`, `life_expectancy`.

Remove the stringency_index as there's not enough data.
```{r}
#ggplot(df, aes(x=vri, y= stringency_index)) + geom_point() + ggtitle("Stringency vs Vaccine Roll-out Index(vri)")
ggplot(df, aes(x=vri, y=`CPI score 2020`)) + geom_point() + ggtitle("Corruption vs Vaccine Roll-out Index(vri)")
#ggplot(df, aes(x=vri, y= `Trust the national government in this country`)) + geom_point() + ggtitle("Trust in government vs Vaccine Roll-out Index(vri)")
ggplot(df, aes(x=vri, y= satisfaction)) + geom_point() + ggtitle("Happiness vs Vaccine Roll-out Index(vri)")
ggplot(df, aes(x=vri, y= extreme_poverty)) + geom_point() + ggtitle("Extreme Poverty vs Vaccine Roll-out Index(vri)")
ggplot(df, aes(x=vri, y= human_development_index)) + geom_point() + ggtitle("Human Development Index vs Vaccine Roll-out Index(vri)")
ggplot(df, aes(x=vri, y= life_expectancy)) + geom_point() + ggtitle("Life Expectancy vs Vaccine Roll-out Index(vri)")

```

##### Health
variables: `cardiovasc_death_rate`/`diabetes_prevalence`, smokers?
```{r}
ggplot(df, aes(x=vri, y= cardiovasc_death_rate)) + geom_point() + ggtitle("Cardiovasc Death Rate vs Vaccine Roll-out Index(vri)")
ggplot(df, aes(x=vri, y= diabetes_prevalence)) + geom_point() + ggtitle("Diabetes Prevalence vs Vaccine Roll-out Index(vri)")
#hospital_beds_per_thousand
ggplot(df, aes(x=vri, y= hospital_beds_per_thousand)) + geom_point() + ggtitle("hospital_beds_per_thousand vs Vaccine Roll-out Index(vri)")
ggplot(df, aes(x=vri, y= GHS_score)) + geom_point() + ggtitle("GHS vs Vaccine Roll-out Index(vri)")
```

##### Correlation Check
```{r}
# correlation matrix
cor_mat <- round(cor(df %>% select(-location), method="spearman"),2)# for non-linear correlation (non-parametric)

## Reorder the correlation matrix
# Refernce: http://www.sthda.com/english/wiki/ggplot2-quick-correlation-matrix-heatmap-r-software-and-data-visualization

reorder_cormat <- function(cor_mat){
  # Use correlation between variables as distance
  dd <- as.dist((1-cor_mat)/2)
  hc <- hclust(dd)
  return (cor_mat[hc$order, hc$order])
}

```


```{r}
## Plotting heatmap
plot_heatmap <- function(cor_mat){
  
  cor_mat <- reorder_cormat(cor_mat)

  ## Remove redundant information (taking the upper triangles values)
  cor_mat[lower.tri(cor_mat)]<- NA
  cor_mat <- melt(cor_mat, na.rm = TRUE)
  
  ggheatmap <- ggplot(cor_mat, aes(Var2, Var1, fill = value))+
 geom_tile(color = "white")+
 scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
   midpoint = 0, limit = c(-1,1), space = "Lab", 
    name="Spearman\nCorrelation") +
  theme_minimal()+ # minimal theme
 theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 8, hjust = 1))+
 coord_fixed()

  ggheatmap + 
geom_text(aes(Var2, Var1, label = value), color = "black", size = 3) +
  theme(
  axis.title.x = element_blank(),
  axis.title.y = element_blank(),
  panel.grid.major = element_blank(),
  panel.border = element_blank(),
  panel.background = element_blank(),
  axis.ticks = element_blank(),
  legend.justification = c(1, 0),
  legend.position = c(0.6, 0.7),
  legend.direction = "horizontal")+
  guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
                title.position = "top", title.hjust = 0.5))

}

plot_heatmap(cor_mat)

```


#### Modelling (RF)

##### Check correlation
```{r}
df <- df %>% select(-location)
cor_mat <- round(cor(df,method="spearman"),2)# for non-linear correlation
## Remove redundant information (taking the upper triangles values)
cor_mat[lower.tri(cor_mat)]<- NA
cor_mat <- melt(cor_mat, na.rm = TRUE)
as.data.frame(cor_mat) %>% filter(value > 0.8 & value != 1)
```

##### Pre-processing
```{r}
min_max_norm <- function(x) {
    (x - min(x)) / (max(x) - min(x))
}
#df
scaled_data <- data.frame(lapply(df[2:13], min_max_norm), vri = df$vri)
# UNSURE RN
scaled_data
```



##### Split data into training and testing
```{r}

ind <- createDataPartition(scaled_data$vri, p = .8,list=FALSE) 
train <- scaled_data[ind,]
X_test <- scaled_data[-ind,] %>% select(-vri)
y_test <- scaled_data[-ind,] %>% select(vri)
dim(train)
dim(X_test)
train

```


##### Tune models on training data with all predictors using grid search with cross-validation
```{r warning=FALSE}
# hyper parameter grid search (definitely need a bit modify)
mtry <-  seq(3, 11, by = 1)
num_trees <- c(100,150,200,250,300,350,400,450,500)


# Manual Search
#control <- trainControl(method="cv", number=3, search="grid")
grid_param <- expand.grid(.mtry=mtry)
modellist <- list()
for (ntree in num_trees) {
	set.seed(3888)
	fit <- train( vri~., 
                      data= train, 
                      method='rf', 
                      tuneGrid=grid_param, 
	                    ntree= ntree,
                      trControl=trainControl(method='cv', 
                        number=3) )
	key <- toString(ntree)
	modellist[[key]] <- fit$finalModel

}


## COMPARE RESULTS

#lowest_mse <- 1
#model_mse <- modellist[[1]]
highest_r2 <- 0
model_r2 <- modellist[[1]]
for (i in c(1:length(modellist))) {

  result <- predict(modellist[[i]], newdata=train %>% select(-vri))
  result_avg <- mean(train$vri)
  r2 = 1 - (sum((train$vri - result)^2))/(sum((train$vri - result_avg)^2))
  if (highest_r2 < r2){
     highest_r2 = r2
     model_r2 = modellist[[i]]
  }
  # mse = min(modellist[[i]]$mse)
  # if (lowest_mse > mse){
  #   lowest_rmse = mse
  #   model_mse = modellist[[i]]
  # }
 
}
#model_mse
model_r2 
highest_r2

```

###### Calculating importance of features to the model: Handling multicollinear features by using conditional permutation

```{r}

## https://cran.r-project.org/web/packages/permimp/vignettes/permimp-package.html
colnames(train)[5] <- "CPI_score_2020"
optimal_rf <- randomForest(VRI ~ ., data= train, mtry = 3, replace = FALSE, 
                         nodesize = 7, keep.forest = TRUE, keep.inbag = FALSE, ntree= 250)
## compute permutation importance
rf_permimp <- permimp(optimal_rf, progressBar = FALSE, conditional = TRUE,scaled = TRUE)

## boxplot
plot(rf_permimp)


```

###### Predict on test sample
```{r}
predictions <- predict(model_r2,newdata = model.matrix(~.,X_test))
predictions
# MSE
sum((y_test-predictions)^2) / length(y_test)
# R squared
result_avg <- mean(y_test$vri)
1 - (sum((y_test$vri - predictions)^2))/(sum((y_test$vri - result_avg)^2))
```


###### Backward Selection(RFE - recursive-feature-elimination)
https://topepo.github.io/caret/recursive-feature-elimination.html#backwards-selection
```{r}
set.seed(3888)

subsets <- c(3:11)

ctrl <- rfeControl(functions = rfFuncs, # using random forest
                   method = "cv",
                   number = 3, # using 3-fold cross validation
                   verbose = FALSE)

rfProfile <- rfe((train %>% select(-vri,-human_development_index)), as.matrix(train %>% select(vri)),
                 sizes = subsets,
                 rfeControl = ctrl)


result <- predict(rfProfile,newdata=train %>% select(-vri))
result_avg <- mean(train$vri)
r2 = 1 - (sum((train$vri - result)^2))/(sum((train$vri - result_avg)^2))


as.data.frame(predictors(rfProfile))
rfProfile$fit
trellis.par.set(caretTheme())
plot(rfProfile, type = c("g", "o"))
r2
```


Optimal Model for RF predict on test data
```{r}
rfProfile
###### Predict on test sample
predictions <- predict(rfProfile,newdata = X_test)
# MSE
sum((y_test-predictions)^2) / length(y_test)
# R squared
result_avg <- mean(y_test$vri)
1 - (sum((y_test$vri - predictions)^2))/(sum((y_test$vri - result_avg)^2))
```


```{r}
rf_df <- df %>% select(vri,life_expectancy,cardiovasc_death_rate,extreme_poverty,
                          hospital_beds_per_thousand,gdp_per_capita,`CPI score 2020`)
colnames(rf_df)[7] <- "CPI_score_2020"

rf <- randomForest(vri ~ ., 
                data= rf_df, ntree=500,mtry=2,
                keep.forest=FALSE, importance=TRUE, seed=3888)

vimp <- varImp(rf,scale = TRUE)
vimp <- vimp[order(vimp$Overall,decreasing = TRUE),,drop = FALSE]
vimp$var <- rownames(vimp)                  
vimp$Overall <- round(vimp$Overall,3)

options(scipen=999)
vimp %>%
  arrange(desc(Overall)) %>%
  ggplot(aes(reorder(var, Overall), Overall)) +
  geom_col() +
  coord_flip() +
  ggtitle("Top important variables") +
  xlab("Factors in order") +
  ylab("Scaled importance")

```

##### Modelling Linear Regression (backwards selection using single p-value
i.e. using drop1() from the full model.
```{r}
# Check strong correlated predictors
cor_mat <- round(cor(df %>% select(-vri)),2) # for linear correlation
cor_mat[lower.tri(cor_mat)]<- NA
cor_mat <- melt(cor_mat, na.rm = TRUE)
as.data.frame(cor_mat) %>% filter(value > 0.8 & value != 1)
```


```{r}
# Full model (Removing non-linear trend predictors + strong correlated predictors)
M1 = lm(vri ~ ., data = df)  #  %>% select(-extreme_poverty,-population_density,-human_development_index,-`CPI score 2020`)

# Try doing backward selection
step_back_aic = step(M1, direction = "backward", trace = FALSE)
summary(step_back_aic)


```


Check assumptions
```{r}
library(ggfortify)
autoplot(step_back_aic, which = 1:2) + theme_bw()
```
Predict
```{r}
predictions <- predict(step_back_aic, newdata = X_test)
# MSE
sum((y_test-predictions)^2) / length(y_test)
# R squared
as.double(cor(y_test, as.data.frame(predictions)) ^ 2)
```


