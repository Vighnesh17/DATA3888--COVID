---
title: "Vaccine(Old)"
author: "Sylvia Liu"
date: "28/04/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(dplyr)
library(readxl)
library(tibble)
library(ggplot2)
library(ggthemes)
library(maps)

library(plotly) # Interactive data visualizations
library(viridis) # Color gradients
library(lubridate)
library(qtlcharts) # Interactive scatter plots 

library(randomForest) 
library(ranger)       # a faster implementation of randomForest
library(caret)        # performe many machine learning models
library(broom)  # try: `install.packages("backports")` if diretly installing broom gives an error

library(reshape2) # to use melt()

library(deSolve)
library(permimp) # for calculating conditional importance in a speedy way

```

## Reading data
```{r}
covid_data <- read.csv("covid_data_latest.csv")
covid_data$date <- as.Date(covid_data$date) #, format = "%d/%m/%y")
covid <- covid_data
```


## Vaccinations progress  

### Vaccine Roll-Out Index (vri) values for the countries

(Reference: https://www.mdpi.com/2076-393X/10/2/194/htm)

```{r vri-func}
ct_model = function(df, log.y = FALSE, model = c("logis", "asymp", "linear"), model2 = "none") {
  # cleaning
  covid_clean = df %>% 
    filter(str_length(iso_code) <= 3) %>% 
    select(iso_code, location, date, people_vaccinated, population, aged_65_older, gdp_per_capita, cardiovasc_death_rate, population_density, hospital_beds_per_thousand, human_development_index, extreme_poverty, diabetes_prevalence, life_expectancy) %>% 
    filter(people_vaccinated != 0 & !is.na(people_vaccinated)) %>% 
    group_by(location) %>% 
    mutate(t_days = difftime(date, min(date), units = "days") %>% as.integer())
  
  # initiate r_list, to store location, r, fit, ... respectively
  r_list = list("location" = c(), "r" = c(), "fit" = c(), "y.real" = c(), "date" = c(), "t_days" = c(), "vri_data" = c(), "iso_code" = c())
  
  ## formulae, based on selected model, people_vaccinated, and log.y
  if (log.y) {
    f2 = formula(log(people_vaccinated) ~ t_days)
    # models
    if (model == "logis") {
      f1 = formula(log(people_vaccinated) ~ SSlogis(t_days, Asym, xmid, scal))
    } else if (model == "asymp") {
      f1 = formula(log(people_vaccinated) ~ SSasymp(t_days, Asym, R0, lrc))
    }
  } else {
    f2 = formula(people_vaccinated ~ t_days)
    # models
    if (model == "logis") {
      f1 = formula(people_vaccinated ~ SSlogis(t_days, Asym, xmid, scal))
    } else if (model == "asymp") {
      f1 = formula(people_vaccinated ~ SSasymp(t_days, Asym, R0, lrc))
    }
  }
  
  ## for each country (location)
  for (loc in unique(covid_clean$location)) {
    # subset cleaned data to one country
    covid_subset = covid_clean %>% filter(location == loc) %>% ungroup()
    iso = unique(covid_subset$iso_code)
    
    # try to fit model
    fit = tryCatch(
      # main function, fit asymptote regression model
      expr = {
        if (model == "linear") {
          lm(f2, data = covid_subset)
        } else {
          nls(f1, data = covid_subset)
        }
      },
      # if error, fit linear model
      error = function(error_message){
        if (model2 == "linear") {
          return( lm(f2, data = covid_subset) )
        } else if (model2 == "none") {
          return( NULL )
        }
      }
    )
    
    # calculate my r value, may need transform before put into vri formula
    if (class(fit) == "lm") {
      r = coef(fit)["t_days"]
    } else if (class(fit) == "nls") {
      if (model == "logis") {scal = coef(fit)["scal"]; r = 1/scal} else
        if (model == "asymp") {lrc = coef(fit)["lrc"]; r = exp(lrc)}
    } else if (class(fit) == "NULL") {
      r = NA
    }
    
    # vri = r * last people_vaccinated / end population
    last_entry = tail(covid_subset, 1)
    vri = r * last_entry$people_vaccinated / last_entry$population
    
    median_data = covid_subset %>% 
      select(-date, -t_days, -location, -iso_code, -people_vaccinated) %>% 
      summarise(across(everything(), median, na.rm = TRUE))
    
    vri_data = median_data %>% 
      mutate(iso_code = iso, location = loc, vri = vri, .before = 1)
    
    r_list[[1]] = c(r_list[[1]], loc)
    r_list[[2]] = c(r_list[[2]], r)
    r_list[[3]] = c(r_list[[3]], list(fit))
    r_list[[4]] = c(r_list[[4]], list(covid_subset$people_vaccinated))
    r_list[[5]] = c(r_list[[5]], list(covid_subset$date))
    r_list[[6]] = c(r_list[[6]], list(covid_subset$t_days))
    r_list[[7]] = c(r_list[[7]], list(vri_data))
    r_list[[8]] = c(r_list[[8]], iso)
  }
  
  ## Measuring model fitness, residual standard error (RSE).
  # for (i in seq_len(length(r_list$fit))) {
  #   if (log.y) {
  #     # residuals = real - fitted
  #     resid = r_list$y.real[[i]] - exp(fitted(r_list$fit[[i]]))
  #     # degrees of freedom = n - k - 1, k = number of parameters
  #     df = summary(r_list$fit[[i]])$df[2]
  #     r_list$rse[[i]] = (sum(resid^2)/df)^(1/2)
  #   } else {
  #     r_list$rse[[i]] = sigma(r_list$fit[[i]])
  #   }
  # }
  
  ## Measuring model fitness, Mean Absolute Scaled Error (MASE).
  # reference: https://people.duke.edu/~rnau/compare.htm
  # https://www.rdocumentation.org/packages/Metrics/versions/0.1.4/topics/mase
  for (i in seq_len(length(r_list$fit))) {
    r_list$mase[[i]] = Metrics::mase(r_list$y.real[[i]], fitted(r_list$fit[[i]]), step_size = 1)
  }
  
  return(r_list)
}
```

```{r}
# Example of use, inspect the r_list to see what's included
r_list1 = ct_model(covid, log.y = FALSE, model = "logis")
vri_data <- data.frame(bind_rows(r_list1$vri_data))
head(vri_data)
```

#### Summary of VRIs
```{r}
### Summary of VRI
summary(vri_data$vri)
ggplot(vri_data,aes(x="",y=vri)) + geom_boxplot(outlier.colour="blue") + ylab("VRI") + xlab("") + ggtitle("Distribution of VRIs") 

```


### The association between vaccination uptake rate and social-economic factors

#### Merging datasets

**I have comment out the government trust dataset as it only contains OECD countries**

Merge joint covid data with vri.

```{r}
corruption <- read_xlsx("CPI2020_GlobalTablesTS_210125.xlsx", sheet=1,skip=2)
corruption <- corruption %>% select (c("ISO3", "CPI score 2020")) 
#corruption


happiness <- read_csv("happiness-cantril-ladder.csv")
happiness <- happiness %>% group_by(Code) %>%
  arrange(Year) %>%
  filter(!is.na(`Life satisfaction in Cantril Ladder (World Happiness Report 2021)`)) %>%
  dplyr::summarise(satisfaction=last(`Life satisfaction in Cantril Ladder (World Happiness Report 2021)`)) 


joint_data <- merge(vri_data,corruption,  by.x=c("iso_code"), by.y=c("ISO3"))

joint_data <- merge(joint_data,happiness, by.x=c("iso_code"), by.y=c("Code"))

# GHE-INDEX
ghs <- read_csv("2021-GHS-Index-April-2022.csv")
ghs <- ghs %>% filter(Year == 2021) %>% select(Country,`OVERALL SCORE`)
## adding iso code to ghs dataset
ghs <- ghs %>% mutate(iso_code = iso.alpha(Country, 3), .before = 1)
ghs <- ghs %>% mutate(
  iso_code = case_when(
    !is.na(iso_code) ~ iso_code,
    Country == "Bosnia and Hercegovina" ~ "BIH",
    Country == "Cabo Verde" ~ "CPV",
    Country == "Congo (Brazzaville)" ~ "COG",
    Country == "Congo (Democratic Republic)" ~ "COD",
    Country == "Côte d'Ivoire" ~ "CIV",
    Country == "eSwatini" ~ "BIH",
    Country == "Kyrgyz Republic" ~ "KGZ",
    Country == "São Tomé and Príncipe" ~ "STP",
    Country == "St Kitts & Nevis" ~ "KNA",
    Country == "St Lucia" ~ "LCA",
    Country == "St Vincent & The Grenadines" ~ "VCT",
    Country == "United Kingdom" ~ "GBR",
    Country == "United States of America" ~ "USA"
  )
)
#setdiff(joint_data$iso_code,ghs$iso_code)

joint_data <- merge(joint_data, ghs[,-2],  by.x=c("iso_code"), by.y=c("iso_code"))
colnames(joint_data)[16] <- "GHS_score"
joint_data
```

#### Preprocessing


Log transformation and min-max normalization
```{r}
# take log for highly skewed variables
vri_extra_logged = joint_data %>% select(-population) %>%
  mutate(
    across(.cols = c(population_density, aged_65_older, gdp_per_capita, hospital_beds_per_thousand, cardiovasc_death_rate, extreme_poverty, diabetes_prevalence),
           ~log(.))
  ) %>% 
  rename_with(.cols = c(population_density, aged_65_older, gdp_per_capita, hospital_beds_per_thousand, cardiovasc_death_rate, extreme_poverty, diabetes_prevalence),
              .fn = ~paste0("log_", .))

vri_extra_logged

min_max_norm <- function(x) {
    (x - min(x,na.rm = TRUE)) / (max(x,na.rm = TRUE) - min(x,na.rm = TRUE))
}

scaled_data <- data.frame(lapply(vri_extra_logged[4:15], min_max_norm), vri = vri_extra_logged$vri)
#scaled_data <- data.frame(lapply(joint_data[4:16], min_max_norm), vri = joint_data$vri)
scaled_data

```
Removing NAs:
```{r}
scaled_data_cleaned <- scaled_data %>% filter( !is.na(vri) & !is.na(log_population_density)& 
                                    !is.na(log_gdp_per_capita) &!is.na(log_aged_65_older)&
                                      !is.na(log_extreme_poverty)&
                                      !is.na(human_development_index)& 
                                      !is.na(log_cardiovasc_death_rate)& 
                                      #!is.na(log_diabetes_prevalence)&
                                      !is.na(log_hospital_beds_per_thousand)) %>% 
                                      
                            select(c(vri,log_gdp_per_capita,log_aged_65_older,log_population_density,
                                     CPI.score.2020,log_extreme_poverty,
                                     satisfaction,life_expectancy,human_development_index,
                                     log_cardiovasc_death_rate,log_diabetes_prevalence,
                                     log_hospital_beds_per_thousand, GHS_score)) 

scaled_data_cleaned
```



#### Selecting Social Economic Factors (Scatter plot + Heatmap)
```{r}
spearman <- cor(scaled_data_cleaned, use="pairwise.complete.obs", method="spearman")

qtlcharts::iplotCorr(
  scaled_data_cleaned,
  reorder=TRUE,
  corr = spearman,
  chartOpts = list(cortitle = "Spearmnan's correlation")
)
```
Remove population_density based on scatter plot and correlation heatmap
```{r}
scaled_data_cleaned <- scaled_data_cleaned %>% select(-log_population_density)
```


#### Modelling (RF)

##### Tune models on training data with all predictors using grid search with cross-validation
```{r warning=FALSE}
# hyper parameter grid search (definitely need a bit modify)
mtry <-  seq(2, 6, by = 1)
num_trees <- c(100,150,200,250,300,350,400,450,500)


# Manual Search
#control <- trainControl(method="cv", number=3, search="grid")
grid_param <- expand.grid(.mtry=mtry)
modellist <- list()
set.seed(388)
for (ntree in num_trees) {
	fit <- train( vri~., 
                      data= scaled_data_cleaned, 
                      method='rf', 
                      tuneGrid=grid_param, 
	                    ntree= ntree,
	                    importance=TRUE,
                      trControl=trainControl(method='cv', 
                        number=5) )
	key <- toString(ntree)
	modellist[[key]] <- fit$finalModel

}


## COMPARE RESULTS

lowest_mse <- 1
model_mse <- modellist[[1]]
highest_r2 <- 0
model_r2 <- modellist[[1]]
  
for (i in c(1:length(modellist))) {

  result <- predict(modellist[[i]], newdata=scaled_data_cleaned %>% select(-vri))
  result_avg <- mean(scaled_data_cleaned$vri)
  mse = mean((scaled_data_cleaned$vri - result)^2)
  r2 = 1 - (sum((scaled_data_cleaned$vri - result)^2))/(sum((scaled_data_cleaned$vri - result_avg)^2))
  if (highest_r2 < r2){
     highest_r2 = r2
     model_r2 = modellist[[i]]
  }
  if (lowest_mse > mse) {
    lowest_mse = mse
    model_mse = modellist[[i]]
  }

 
}
model_mse
model_r2
lowest_mse
highest_r2
```

###### Calculating importance of features to the model: Handling multicollinear features by using conditional permutation

```{r}

## https://cran.r-project.org/web/packages/permimp/vignettes/permimp-package.html

set.seed(388)
optimal_rf <- randomForest(vri ~ ., data= scaled_data_cleaned, mtry = 2, keep.forest = TRUE, keep.inbag = FALSE, ntree= 200)
## compute permutation importance
rf_permimp <- permimp(optimal_rf, progressBar = FALSE, conditional = TRUE,scaled = TRUE, thresholdDiagnostics = TRUE,type="response")

## boxplot
plot(rf_permimp)

rf_permimp$values

vimp <- as.data.frame(rf_permimp$values)
colnames(vimp)[1] <- "importance"
vimp <- round(vimp, 4)
vimp$var <- row.names(vimp)
vimp

options(scipen=999)
vimp <- vimp %>%
  arrange(desc(importance)) %>%
  slice(1:5)


vimp %>%
  ggplot(aes(reorder(var,importance), importance)) +
  geom_col(fill="steelblue") +
  coord_flip() +
  theme_bw()+
  ggtitle("Top 5 important variables") +
  xlab("Factors in order") +
  ylab("Scaled importance")

```
