---
title: "classify_VRI"
author: "Xinzhi Wang"
date: '2022-05-19'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(dplyr)
library(readxl)
library(tibble)
library(ggplot2)
library(ggthemes)
library(maps)

library(plotly) # Interactive data visualizations
library(viridis) # Color gradients
library(lubridate)

library(randomForest) 
library(ranger)       # a faster implementation of randomForest
library(caret)        # performe many machine learning models
library(broom)  # try: `install.packages("backports")` if diretly installing broom gives an error

library(reshape2) # to use melt()

library(deSolve)
library(permimp) # for calculating conditional importance in a speedy way
```


## Reading data
```{r}
covid <- read.csv("./data/covid_data_latest.csv")
covid$date <- as.Date(covid$date) #, format = "%d/%m/%y")
#head(covid_data)
```


## Vaccinations progress  

### Vaccine Roll-Out Index (vri) values for the countries

(Reference: https://www.mdpi.com/2076-393X/10/2/194/htm)

> **Estimate Vaccine Uptakes Rates r* for Countries**


```{r}
## NEW
covid_clean = covid %>% 
  filter(str_length(iso_code) <= 3) %>% 
  select(iso_code, location, date, people_vaccinated,population) %>% 
  remove_missing() %>%
  filter(people_vaccinated != 0) %>% 
  group_by(location) %>% 
  mutate(t_days = difftime(date, min(date), units = "days") %>% as.integer())
```

```{r}
## calculate vri using: est_rate * d/N
estimate_vri <- function(data, r){
  vri <- r * (data$people_vaccinated[length(data$people_vaccinated)]) / data$population[1]
  
  return(vri)
}
```


```{r}
covid_subset = covid_clean %>% filter(location == "Japan")
  
  # try to fit model
  fit = tryCatch(
    # main function, fit asymptote regression model
    expr = {
      nls(log(people_vaccinated) ~ SSasymp(t_days, Asym, R0, lrc), data = covid_subset)
    },
    # if error, fit linear model
    error = function(error_message){
      return( lm(log(people_vaccinated) ~ t_days, data = covid_subset) )
    }
  )
  
# temp <- data.frame(index = c(1:length(predict(formu))), predict = predict(formu))


# ggplot(temp,aes(index, predict))+geom_line()
ggplot(covid_subset, aes(x = date, y = predict(fit))) + 
  geom_line() + 
  geom_point(aes(y=log(people_vaccinated)))+
  theme_bw()+
  theme(panel.grid.minor = element_blank(),panel.grid.major = element_blank())+xlab("Fermentation days")+ylab("Dry weight of biomass (mg)")
```


```{r logy-asympreg}
# initiate r1_list, to store location, r, fit, respectively
r1_list = list("location" = c(), "r" = c(), "fit" = c())
vri_data <- NULL

#covid_clean$location

## for each country (location)
for (loc in unique(covid_clean$location)) {
  # subset cleaned data to one country
  covid_subset = covid_clean %>% filter(location == loc)
  
  # try to fit model
  fit = tryCatch(
    # main function, fit asymptote regression model
    expr = {
      nls(people_vaccinated ~ SSlogis(t_days, K, xmid, scal), data = covid_subset)
    },
    # if error, fit linear model
    error = function(error_message){
      return( lm(log(people_vaccinated) ~ t_days, data = covid_subset) )
    }
  )
  
  # calculate my r value, may need transform before put into vri formula
  if (class(fit) == "lm") {
    r = coef(fit)["t_days"]
  } else if (class(fit) == "nls") {
    scal = coef(fit)["scal"]
    r = 1/scal
  }
  
  r1_list$location = c(r1_list$location, loc)
  r1_list$r = c(r1_list$r, r)
  r1_list$fit = c(r1_list$fit, list(fit))
  
  vri <- estimate_vri(covid_clean, r)
  
  
  temp <- data.frame(location = loc, vri = vri,
                      aged_65_older = covid[covid$location == loc, ]$aged_65_older[1],
                      gdp_per_capita = covid[covid$location == loc, ]$gdp_per_capita[1],
                      cardiovasc_death_rate = covid[covid$location == loc, ]$cardiovasc_death_rate[1],
                      population_density = covid[covid$location == loc, ]$population_density[1],
                      hospital_beds_per_thousand = covid[covid$location == loc,]$hospital_beds_per_thousand[1],
                      human_development_index = covid[covid$location == loc, ]$human_development_index[1],
                      extreme_poverty = covid[covid$location == loc, ]$extreme_poverty[1],
                      diabetes_prevalence = covid[covid$location == loc, ]$diabetes_prevalence[1],
                      life_expectancy = covid[covid$location == loc, ]$life_expectancy[1],
                      iso_code = covid[covid$location == loc, ]$iso_code[1])


  vri_data <- rbind(vri_data, temp)
}


## Measuring model fitness, residual standard error (RSE).
for (i in seq_len(length(r1_list$fit))) {
  r1_list$rse[[i]] = sigma(r1_list$fit[[i]])
}


## Country using linear model 
unwanted_loc <- r1_list$location[names(r1_list$r) == "t_days"]
vri_data <- vri_data %>% filter (!(location %in% unwanted_loc))
```




```{r}
corruption <- read_xlsx("data/CPI2020_GlobalTablesTS_210125.xlsx", sheet=1,skip=2)
corruption <- corruption %>% select (c("ISO3", "CPI score 2020")) 
#corruption

happiness <- read_csv("data/happiness-cantril-ladder.csv")
happiness <- happiness %>% group_by(Code) %>%
  arrange(Year) %>%
  filter(!is.na(`Life satisfaction in Cantril Ladder (World Happiness Report 2021)`)) %>%
  dplyr::summarise(satisfaction=last(`Life satisfaction in Cantril Ladder (World Happiness Report 2021)`)) 


joint_data <- merge(vri_data,corruption,  by.x=c("iso_code"), by.y=c("ISO3"))

joint_data <- merge(joint_data,happiness, by.x=c("iso_code"), by.y=c("Code"))

# GHE-INDEX
ghs <- read_csv("data/2021-GHS-Index-April-2022.csv")
ghs <- ghs %>% filter(Year == 2021) %>% select(Country,`OVERALL SCORE`)

joint_data <- merge(joint_data, ghs,  by.x=c("location"), by.y=c("Country"))
colnames(joint_data)[15] <- "GHS_score"
joint_data
```

```{r}
# Basic scatter plot
df <- joint_data %>% filter(!is.na(population_density) # set a threshold to remove outliers:
                                    &!is.na(gdp_per_capita) &!is.na(aged_65_older)&
                                      !is.na(extreme_poverty)&
                                      !is.na(human_development_index)& 
                                      !is.na(cardiovasc_death_rate)& 
                                      !is.na(diabetes_prevalence)&
                                      !is.na(hospital_beds_per_thousand)) %>% 
                                      
                            select(c(location,vri,population_density,gdp_per_capita,aged_65_older,
                                     `CPI score 2020`,
                                     satisfaction,extreme_poverty,human_development_index,life_expectancy,
                                      cardiovasc_death_rate,diabetes_prevalence,
                                      hospital_beds_per_thousand, GHS_score)) 

df
```


```{r}
library(sigmoid)
zscore <- function(x) {
  # x is a variable (col) in a dataframe
  zscore = (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
  return(zscore)
}

min_max_norm <- function(x) {
    (x - min(x)) / (max(x) - min(x))
}

df <- df %>% filter(vri < 0.01)
#df
scaled_data <- data.frame(vri = df$vri, lapply(df %>% select(-location, -vri), min_max_norm))
# UNSURE RN
scaled_data$vri <- sigmoid(zscore(scaled_data$vri))
```

clustering countries on most improtant variables:

```{r}
variables <- df %>% select(location, vri,`CPI score 2020`,population_density,gdp_per_capita,cardiovasc_death_rate,human_development_index)

colnames(variables)
variables_mat <- as.matrix(variables[,-1])
rownames(variables_mat) <- as.matrix(variables[,1])

#next two lines of code are used to determine the best number of clusters
fviz_nbclust(variables_mat,kmeans,method= "wss")
fviz_nbclust(variables_mat,kmeans,method= "silhouette")

km <- kmeans(variables_mat,3,nstart = 25) #3 clusters
print(km)
fviz_cluster(km,variables_mat, labelsize = 5) #visualise cluster

```


Setting up the threshold
```{r}
boxplot(scaled_data$vri)

low <- quantile(scaled_data$vri)[2]

high <- quantile(scaled_data$vri)[4]
```

```{r}
scaled_data$label <- ifelse(scaled_data$vri < high , 0, 1)
```





```{r}
set.seed(1)

X = scaled_data %>% select(-vri, -label)
y = scaled_data$label

cvK <- 5  # number of CV folds
cv_acc5_50times_svm = cv_acc5_svm = cv_acc5_50times_rf = cv_acc5_rf = c()

n_sim = 50 ## number of repeats
for (i in 1:n_sim) {

  cvSets <- cvTools::cvFolds(nrow(X), cvK)  # permute all the data, into 5 folds
  cv_svm <- c()
  
  for (j in 1:cvK) {
    test_id = cvSets$subsets[cvSets$which == j]
    X_test = X[test_id, ]
    X_train = X[-test_id, ]
    y_test = y[test_id]
    y_train = y[-test_id]
    
    ## SVM
    svm_res <- e1071::svm(x = X_train, y = as.factor(y_train))
    fit <- predict(svm_res, X_test)
    cv_acc5_svm[j] = mean(fit == y_test)
    
    ## RF
    rf <- randomForest(x = X_train, y = as.factor(y_train))
    rf <- predict(rf, X_test)
    
    cv_acc5_rf[j] = mean(rf == y_test)
  }
  
  cv_acc5_50times_svm <- append(cv_acc5_50times_svm, mean(cv_acc5_svm))
  cv_acc5_50times_rf <- append(cv_acc5_50times_rf, mean(cv_acc5_rf))
} ## end for

boxplot(cv_acc5_50times_svm)
boxplot(cv_acc5_50times_rf)
```





```{r warning=FALSE}
# hyper parameter grid search (definitely need a bit modify)
set.seed(1)
mtry <-  seq(2, 12, by = 1)
num_trees <- c(100,150,200,250,300,350,400,450,500)


# Manual Search
#control <- trainControl(method="cv", number=3, search="grid")
grid_param <- expand.grid(.mtry=mtry)
modellist <- list()
for (ntree in num_trees) {
	fit <- train( vri~., 
                      data= scaled_data, 
                      method='rf', 
                      tuneGrid=grid_param, 
	                    ntree= ntree,
                      trControl=trainControl(method='cv', 
                        number=3) )
	key <- toString(ntree)
	modellist[[key]] <- fit$finalModel

}


## COMPARE RESULTS

#lowest_mse <- 1
#model_mse <- modellist[[1]]
highest_r2 <- 0
model_r2 <- modellist[[1]]
for (i in c(1:length(modellist))) {

  result <- predict(modellist[[i]], newdata=scaled_data%>% select(-vri))
  result_avg <- mean(scaled_data$vri)
  r2 = 1 - (sum((scaled_data$vri - result)^2))/(sum((scaled_data$vri - result_avg)^2))
  if (highest_r2 < r2){
     highest_r2 = r2
     model_r2 = modellist[[i]]
  }
  # mse = min(modellist[[i]]$mse)
  # if (lowest_mse > mse){
  #   lowest_rmse = mse
  #   model_mse = modellist[[i]]
  # }
 
}
#model_mse
model_r2 
highest_r2

```






















