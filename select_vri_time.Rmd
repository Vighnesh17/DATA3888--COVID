---
title: "Select_VRI_Time"
author: "Xinzhi Wang"
date: '2022-05-19'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(dplyr)
library(readxl)
library(tibble)
library(ggplot2)
library(ggthemes)
library(maps)

library(plotly) # Interactive data visualizations
library(viridis) # Color gradients
library(lubridate)

library(randomForest) 
library(ranger)       # a faster implementation of randomForest
library(caret)        # performe many machine learning models
library(broom)  # try: `install.packages("backports")` if diretly installing broom gives an error

library(reshape2) # to use melt()

library(deSolve)
library(permimp) # for calculating conditional importance in a speedy way
```


## Reading data
```{r}
covid <- read.csv("./data/covid_data_latest.csv")
covid$date <- as.Date(covid$date) #, format = "%d/%m/%y")
#head(covid_data)
```

```{r vri-func}
ct_model = function(df, log.y = FALSE, model = c("logis", "asymp", "linear"), model2 = "none") {
  # cleaning
  covid_clean = df %>% 
    filter(str_length(iso_code) <= 3) %>% 
    select(iso_code, location, date, people_vaccinated, population, aged_65_older, gdp_per_capita, cardiovasc_death_rate, population_density, hospital_beds_per_thousand, human_development_index, extreme_poverty, diabetes_prevalence, life_expectancy) %>% 
    filter(people_vaccinated != 0 & !is.na(people_vaccinated)) %>% 
    group_by(location) %>% 
    mutate(t_days = difftime(date, min(date), units = "days") %>% as.integer())
  
  # initiate r_list, to store location, r, fit, ... respectively
  r_list = list("location" = c(), "r" = c(), "fit" = c(), "y.real" = c(), "date" = c(), "t_days" = c(), "vri_data" = c(), "iso_code" = c())
  
  ## formulae, based on selected model, people_vaccinated, and log.y
  if (log.y) {
    f2 = formula(log(people_vaccinated) ~ t_days)
    # models
    if (model == "logis") {
      f1 = formula(log(people_vaccinated) ~ SSlogis(t_days, Asym, xmid, scal))
    } else if (model == "asymp") {
      f1 = formula(log(people_vaccinated) ~ SSasymp(t_days, Asym, R0, lrc))
    }
  } else {
    f2 = formula(people_vaccinated ~ t_days)
    # models
    if (model == "logis") {
      f1 = formula(people_vaccinated ~ SSlogis(t_days, Asym, xmid, scal))
    } else if (model == "asymp") {
      f1 = formula(people_vaccinated ~ SSasymp(t_days, Asym, R0, lrc))
    }
  }
  
  ## for each country (location)
  for (loc in unique(covid_clean$location)) {
    # subset cleaned data to one country
    covid_subset = covid_clean %>% filter(location == loc) %>% ungroup()
    iso = unique(covid_subset$iso_code)
    
    # try to fit model
    fit = tryCatch(
      # main function, fit asymptote regression model
      expr = {
        if (model == "linear") {
          lm(f2, data = covid_subset)
        } else {
          nls(f1, data = covid_subset)
        }
      },
      # if error, fit linear model
      error = function(error_message){
        if (model2 == "linear") {
          return( lm(f2, data = covid_subset) )
        } else if (model2 == "none") {
          return( NULL )
        }
      }
    )
    
    # calculate my r value, may need transform before put into vri formula
    if (class(fit) == "lm") {
      r = coef(fit)["t_days"]
    } else if (class(fit) == "nls") {
      if (model == "logis") {scal = coef(fit)["scal"]; r = 1/scal} else
        if (model == "asymp") {lrc = coef(fit)["lrc"]; r = exp(lrc)}
    } else if (class(fit) == "NULL") {
      r = NA
    }
    
    # vri = r * last people_vaccinated / end population
    last_entry = tail(covid_subset, 1)
    vri = r * last_entry$people_vaccinated / last_entry$population
    
    median_data = covid_subset %>% 
      select(-date, -t_days, -location, -iso_code, -people_vaccinated) %>% 
      summarise(across(everything(), median, na.rm = TRUE))
    
    vri_data = median_data %>% 
      mutate(iso_code = iso, location = loc, vri = vri, .before = 1)
    
    r_list[[1]] = c(r_list[[1]], loc)
    r_list[[2]] = c(r_list[[2]], r)
    r_list[[3]] = c(r_list[[3]], list(fit))
    r_list[[4]] = c(r_list[[4]], list(covid_subset$people_vaccinated))
    r_list[[5]] = c(r_list[[5]], list(covid_subset$date))
    r_list[[6]] = c(r_list[[6]], list(covid_subset$t_days))
    r_list[[7]] = c(r_list[[7]], list(vri_data))
    r_list[[8]] = c(r_list[[8]], iso)
  }
  
  ## Measuring model fitness, residual standard error (RSE).
  # for (i in seq_len(length(r_list$fit))) {
  #   if (log.y) {
  #     # residuals = real - fitted
  #     resid = r_list$y.real[[i]] - exp(fitted(r_list$fit[[i]]))
  #     # degrees of freedom = n - k - 1, k = number of parameters
  #     df = summary(r_list$fit[[i]])$df[2]
  #     r_list$rse[[i]] = (sum(resid^2)/df)^(1/2)
  #   } else {
  #     r_list$rse[[i]] = sigma(r_list$fit[[i]])
  #   }
  # }
  
  ## Measuring model fitness, Mean Absolute Scaled Error (MASE).
  # reference: https://people.duke.edu/~rnau/compare.htm
  # https://www.rdocumentation.org/packages/Metrics/versions/0.1.4/topics/mase
  for (i in seq_len(length(r_list$fit))) {
    r_list$mase[[i]] = Metrics::mase(r_list$y.real[[i]], fitted(r_list$fit[[i]]), step_size = 1)
  }
  
  return(r_list)
}
```

```{r}
start <- min(covid$date[!is.na(covid$people_vaccinated)])
end <- start %m+% months(4)

r_list4 = ct_model(covid[start <= covid$date & covid$date < end, ], log.y = FALSE, model = "logis")
temp_data <- data.frame(bind_rows(r_list4$vri_data))
temp_data <- data.frame(vri4 = temp_data$vri, temp_data %>% select(-vri))
vri_data <- temp_data


start <- min(covid$date[!is.na(covid$people_vaccinated)])
start <- start %m+% months(4)
end <- start %m+% months(8)

r_list8 = ct_model(covid[start <= covid$date & covid$date < end, ], log.y = FALSE, model = "logis")
temp_data <- data.frame(bind_rows(r_list8$vri_data))
temp_data <- data.frame(vri8 = temp_data$vri, location = temp_data$location)
vri_data <- merge(vri_data, temp_data, by = "location")

start <- min(covid$date[!is.na(covid$people_vaccinated)])
start <- start %m+% months(8)

r_listf = ct_model(covid[start <= covid$date & covid$date < end, ], log.y = FALSE, model = "logis")
temp_data <- data.frame(bind_rows(r_listf$vri_data))
temp_data <- data.frame(vrif = temp_data$vri, location = temp_data$location)
vri_data <- merge(vri_data, temp_data, by = "location")

# Example of use, inspect the r_list to see what's included

head(vri_data)
```

```{r}
corruption <- read_xlsx("data/CPI2020_GlobalTablesTS_210125.xlsx", sheet=1,skip=2)
corruption <- corruption %>% select (c("ISO3", "CPI score 2020")) 
#corruption

happiness <- read_csv("data/happiness-cantril-ladder.csv")
happiness <- happiness %>% group_by(Code) %>%
  arrange(Year) %>%
  filter(!is.na(`Life satisfaction in Cantril Ladder (World Happiness Report 2021)`)) %>%
  dplyr::summarise(satisfaction=last(`Life satisfaction in Cantril Ladder (World Happiness Report 2021)`)) 


joint_data <- merge(vri_data, corruption,  by.x=c("iso_code"), by.y=c("ISO3"))

joint_data <- merge(joint_data,happiness, by.x=c("iso_code"), by.y=c("Code"))

# GHE-INDEX
ghs <- read_csv("data/2021-GHS-Index-April-2022.csv")
ghs <- ghs %>% filter(Year == 2021) %>% select(Country,`OVERALL SCORE`)
## adding iso code to ghs dataset
ghs <- ghs %>% mutate(iso_code = iso.alpha(Country, 3), .before = 1)
ghs <- ghs %>% mutate(
  iso_code = case_when(
    !is.na(iso_code) ~ iso_code,
    Country == "Bosnia and Hercegovina" ~ "BIH",
    Country == "Cabo Verde" ~ "CPV",
    Country == "Congo (Brazzaville)" ~ "COG",
    Country == "Congo (Democratic Republic)" ~ "COD",
    Country == "Côte d'Ivoire" ~ "CIV",
    Country == "eSwatini" ~ "BIH",
    Country == "Kyrgyz Republic" ~ "KGZ",
    Country == "São Tomé and Príncipe" ~ "STP",
    Country == "St Kitts & Nevis" ~ "KNA",
    Country == "St Lucia" ~ "LCA",
    Country == "St Vincent & The Grenadines" ~ "VCT",
    Country == "United Kingdom" ~ "GBR",
    Country == "United States of America" ~ "USA"
  )
)
#setdiff(joint_data$iso_code,ghs$iso_code)

joint_data <- merge(joint_data, ghs[,-2],  by.x=c("iso_code"), by.y=c("iso_code"))
colnames(joint_data)[18] <- "GHS_score"
joint_data
```


#### Preprocessing


Log transformation and min-max normalization
```{r}
# take log for highly skewed variables
vri_extra_logged = joint_data %>% select(-population) %>%
  mutate(
    across(.cols = c(population_density, aged_65_older, gdp_per_capita, hospital_beds_per_thousand, cardiovasc_death_rate, extreme_poverty, diabetes_prevalence),
           ~log(.))
  ) %>% 
  rename_with(.cols = c(population_density, aged_65_older, gdp_per_capita, hospital_beds_per_thousand, cardiovasc_death_rate, extreme_poverty, diabetes_prevalence),
              .fn = ~paste0("log_", .))

vri_extra_logged

min_max_norm <- function(x) {
    (x - min(x,na.rm = TRUE)) / (max(x,na.rm = TRUE) - min(x,na.rm = TRUE))
}

scaled_data <- data.frame(lapply(vri_extra_logged %>% select(-iso_code, -location, -vri4, -vri8, -vrif), min_max_norm), vri4 = vri_extra_logged$vri4, vri8 = vri_extra_logged$vri8, vrif = vri_extra_logged$vrif)
# #scaled_data <- data.frame(lapply(joint_data[4:16], min_max_norm), vri = joint_data$vri)
scaled_data

```

Removing NAs:
```{r}
scaled_data_cleaned <- scaled_data %>% filter(!is.na(vri4) &
                                                !is.na(vri8) &
                                                !is.na(vrif) &
                                                !is.na(log_population_density) &
                                                !is.na(log_gdp_per_capita) &
                                                !is.na(log_aged_65_older)&
                                                !is.na(log_extreme_poverty)&
                                                !is.na(human_development_index)&
                                                !is.na(log_cardiovasc_death_rate)&
                                                !is.na(log_hospital_beds_per_thousand)) %>%
  select(c(vri4, vri8, vrif, log_gdp_per_capita,log_aged_65_older,log_population_density,CPI.score.2020,
           log_extreme_poverty,satisfaction,life_expectancy,human_development_index,
           log_cardiovasc_death_rate,log_diabetes_prevalence,log_hospital_beds_per_thousand, GHS_score)) 

scaled_data_cleaned
```


```{r warning=FALSE}
# hyper parameter grid search (definitely need a bit modify)
set.seed(1)
mtry <-  seq(2, 12, by = 1)
num_trees <- c(100,150,200,250,300,350,400,450,500)


# Manual Search
#control <- trainControl(method="cv", number=3, search="grid")
grid_param <- expand.grid(.mtry=mtry)
modellist <- list()
for (ntree in num_trees) {
	fit <- train( vri4~., 
                      data= scaled_data_cleaned %>% select(-vri8, -vrif), 
                      method='rf', 
                      tuneGrid=grid_param, 
	                    ntree= ntree,
                      trControl=trainControl(method='cv', 
                        number=3) )
	key <- toString(ntree)
	modellist[[key]] <- fit$finalModel

}


## COMPARE RESULTS

lowest_mse <- 1
model_mse <- modellist[[1]]
highest_r2 <- 0
model_r2 <- modellist[[1]]

for (i in c(1:length(modellist))) {

  result <- predict(modellist[[i]], newdata=scaled_data_cleaned %>% select(-vri4, -vri8, -vrif))
  result_avg <- mean(scaled_data_cleaned$vri4)
  mse = mean((scaled_data_cleaned$vri4 - result)^2)
  r2 = 1 - (sum((scaled_data_cleaned$vri4 - result)^2))/(sum((scaled_data_cleaned$vri4 - result_avg)^2))
  if (highest_r2 < r2){
     highest_r2 = r2
     model_r2 = modellist[[i]]
  }
  if (lowest_mse > mse) {
    lowest_mse = mse
    model_mse = modellist[[i]]
  }
 
}

model_mse
model_r2
lowest_mse
highest_r2

```
```{r warning=FALSE}
# hyper parameter grid search (definitely need a bit modify)
set.seed(1)
mtry <-  seq(2, 12, by = 1)
num_trees <- c(100,150,200,250,300,350,400,450,500)


# Manual Search
#control <- trainControl(method="cv", number=3, search="grid")
grid_param <- expand.grid(.mtry=mtry)
modellist <- list()
for (ntree in num_trees) {
	fit <- train( vri8~., 
                      data= scaled_data_cleaned %>% select(-vri4, -vrif), 
                      method='rf', 
                      tuneGrid=grid_param, 
	                    ntree= ntree,
                      trControl=trainControl(method='cv', 
                        number=3) )
	key <- toString(ntree)
	modellist[[key]] <- fit$finalModel

}


## COMPARE RESULTS

lowest_mse <- 1
model_mse <- modellist[[1]]
highest_r2 <- 0
model_r2 <- modellist[[1]]
highest_r2 <- 0
model_r2 <- modellist[[1]]

for (i in c(1:length(modellist))) {

  result <- predict(modellist[[i]], newdata=scaled_data_cleaned %>% select(-vri4, -vri8, -vrif))
  result_avg <- mean(scaled_data_cleaned$vri8)
  mse = mean((scaled_data_cleaned$vri8 - result)^2)
  r2 = 1 - (sum((scaled_data_cleaned$vri8 - result)^2))/(sum((scaled_data_cleaned$vri8 - result_avg)^2))
  if (highest_r2 < r2){
     highest_r2 = r2
     model_r2 = modellist[[i]]
  }
  if (lowest_mse > mse) {
    lowest_mse = mse
    model_mse = modellist[[i]]
  }
 
}

model_mse
model_r2
lowest_mse
highest_r2

```


```{r warning=FALSE}
# hyper parameter grid search (definitely need a bit modify)
set.seed(1)
mtry <-  seq(2, 12, by = 1)
num_trees <- c(100,150,200,250,300,350,400,450,500)


# Manual Search
#control <- trainControl(method="cv", number=3, search="grid")
grid_param <- expand.grid(.mtry=mtry)
modellist <- list()
for (ntree in num_trees) {
	fit <- train( vrif~., 
                      data= scaled_data_cleaned %>% select(-vri8, -vri4), 
                      method='rf', 
                      tuneGrid=grid_param, 
	                    ntree= ntree,
                      trControl=trainControl(method='cv', 
                        number=3) )
	key <- toString(ntree)
	modellist[[key]] <- fit$finalModel

}


## COMPARE RESULTS

lowest_mse <- 1
model_mse <- modellist[[1]]
highest_r2 <- 0
model_r2 <- modellist[[1]]
highest_r2 <- 0
model_r2 <- modellist[[1]]

for (i in c(1:length(modellist))) {

  result <- predict(modellist[[i]], newdata=scaled_data_cleaned %>% select(-vri4, -vri8, -vrif))
  result_avg <- mean(scaled_data_cleaned$vrif)
  mse = mean((scaled_data_cleaned$vrif - result)^2)
  r2 = 1 - (sum((scaled_data_cleaned$vrif - result)^2))/(sum((scaled_data_cleaned$vrif - result_avg)^2))
  if (highest_r2 < r2){
     highest_r2 = r2
     model_r2 = modellist[[i]]
  }
  if (lowest_mse > mse) {
    lowest_mse = mse
    model_mse = modellist[[i]]
  }
 
}

model_mse
model_r2
lowest_mse
highest_r2

```







