---
title: "Select_VRI_Time"
author: "Xinzhi Wang"
date: '2022-05-19'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(dplyr)
library(readxl)
library(tibble)
library(ggplot2)
library(ggthemes)
library(maps)

library(plotly) # Interactive data visualizations
library(viridis) # Color gradients
library(lubridate)

library(randomForest) 
library(ranger)       # a faster implementation of randomForest
library(caret)        # performe many machine learning models
library(broom)  # try: `install.packages("backports")` if diretly installing broom gives an error

library(reshape2) # to use melt()

library(deSolve)
library(permimp) # for calculating conditional importance in a speedy way
```


## Reading data
```{r}
covid <- read.csv("./data/covid_data_latest.csv")
covid$date <- as.Date(covid$date) #, format = "%d/%m/%y")
#head(covid_data)
```


## Vaccinations progress  

### Vaccine Roll-Out Index (vri) values for the countries

(Reference: https://www.mdpi.com/2076-393X/10/2/194/htm)

> **Estimate Vaccine Uptakes Rates r* for Countries**


```{r}
## NEW
covid_clean = covid %>% 
  filter(str_length(iso_code) <= 3) %>% 
  select(iso_code, location, date, people_vaccinated,population) %>% 
  remove_missing() %>%
  filter(people_vaccinated != 0) %>% 
  group_by(location) %>% 
  mutate(t_days = difftime(date, min(date), units = "days") %>% as.integer())
```

```{r}
## calculate vri using: est_rate * d/N
estimate_vri <- function(data, r){
  vri <- r * (data$people_vaccinated[length(data$people_vaccinated)]) / data$population[1]
  
  return(vri)
}
```

```{r}
d=as.Date('2010-08-01')

d %m+% months(6)
```

# The first 4 month
```{r logy-asympreg}
# initiate r1_list, to store location, r, fit, respectively
r1_list = list("location" = c(), "r" = c(), "fit" = c())
vri_data <- NULL

#covid_clean$location

## for each country (location)
for (loc in unique(covid_clean$location)) {
  # subset cleaned data to one country
  covid_subset = covid_clean %>% filter(location == loc)
  
  
  start <- min(covid_subset$date[!is.na(covid_subset$people_vaccinated)])
  end <- start %m+% months(4)

  print(loc)
  print(start)
  print(end)
  
  
  
  covid_subset <- covid_subset[start <= covid_subset$date & covid_subset$date < end, ]
  
  # try to fit model
  fit = tryCatch(
    # main function, fit asymptote regression model
    expr = {
      nls(people_vaccinated ~ SSlogis(t_days, K, xmid, scal), data = covid_subset)
    },
    # if error, fit linear model
    error = function(error_message){
      return( lm(log(people_vaccinated) ~ t_days, data = covid_subset) )
    }
  )
  
  # calculate my r value, may need transform before put into vri formula
  if (class(fit) == "lm") {
    r = coef(fit)["t_days"]
  } else if (class(fit) == "nls") {
    scal = coef(fit)["scal"]
    r = 1/scal
  }
  
  r1_list$location = c(r1_list$location, loc)
  r1_list$r = c(r1_list$r, r)
  r1_list$fit = c(r1_list$fit, list(fit))
  
  vri <- estimate_vri(covid_clean, r)
  
  
  temp <- data.frame(location = loc, vri4 = vri)


  vri_data <- rbind(vri_data, temp)
}


## Measuring model fitness, residual standard error (RSE).
for (i in seq_len(length(r1_list$fit))) {
  r1_list$rse[[i]] = sigma(r1_list$fit[[i]])
}


## Country using linear model 
unwanted_loc <- r1_list$location[names(r1_list$r) == "t_days"]
vri_data <- vri_data %>% filter (!(location %in% unwanted_loc))
```


# 8 month
```{r logy-asympreg}
# initiate r1_list, to store location, r, fit, respectively
r1_list = list("location" = c(), "r" = c(), "fit" = c())
temp_data <- NULL

#covid_clean$location

## for each country (location)
for (loc in unique(covid_clean$location)) {
  # subset cleaned data to one country
  covid_subset = covid_clean %>% filter(location == loc)
  
  start <- min(covid_subset$date[!is.na(covid_subset$people_vaccinated)])
  start <- start %m+% months(4)
  end <- start %m+% months(9)

  covid_subset <- covid_subset[start <= covid_subset$date & covid_subset$date < end, ]
  
  # try to fit model
  fit = tryCatch(
    # main function, fit asymptote regression model
    expr = {
      nls(people_vaccinated ~ SSlogis(t_days, K, xmid, scal), data = covid_subset)
    },
    # if error, fit linear model
    error = function(error_message){
      # return( lm(log(people_vaccinated) ~ t_days, data = covid_subset) )
    }
  )
  
  # calculate my r value, may need transform before put into vri formula
  if (class(fit) == "lm") {
    r = coef(fit)["t_days"]
  } else if (class(fit) == "nls") {
    scal = coef(fit)["scal"]
    r = 1/scal
  }
  
  r1_list$location = c(r1_list$location, loc)
  r1_list$r = c(r1_list$r, r)
  r1_list$fit = c(r1_list$fit, list(fit))
  
  vri <- estimate_vri(covid_clean, r)
  
  
  temp <- data.frame(location = loc, vri8 = vri)


  temp_data <- rbind(temp_data, temp)
}


## Measuring model fitness, residual standard error (RSE).
# for (i in seq_len(length(r1_list$fit))) {
#   r1_list$rse[[i]] = sigma(r1_list$fit[[i]])
# }
# 
# 
# ## Country using linear model 
# unwanted_loc <- r1_list$location[names(r1_list$r) == "t_days"]
# temp_data <- temp_data %>% filter (!(location %in% unwanted_loc))

vri_data <- merge(vri_data, temp_data, by = "location")
```


# Full time
```{r logy-asympreg}
# initiate r1_list, to store location, r, fit, respectively
r1_list = list("location" = c(), "r" = c(), "fit" = c())
temp_data <- NULL

#covid_clean$location

## for each country (location)
for (loc in unique(covid_clean$location)) {
  # subset cleaned data to one country
  covid_subset = covid_clean %>% filter(location == loc)
  
  start <- min(covid_subset$date[!is.na(covid_subset$people_vaccinated)])
  start <- start %m+% months(8)
  # end <- start %m+% months(8)
  # 
  covid_subset <- covid_subset[start <= covid_subset$date, ]
  
  # try to fit model
  fit = tryCatch(
    # main function, fit asymptote regression model
    expr = {
      nls(people_vaccinated ~ SSlogis(t_days, K, xmid, scal), data = covid_subset)
    },
    # if error, fit linear model
    error = function(error_message){
      # return( lm(log(people_vaccinated) ~ t_days, data = covid_subset) )
    }
  )
  
  # calculate my r value, may need transform before put into vri formula
  if (class(fit) == "lm") {
    r = coef(fit)["t_days"]
  } else if (class(fit) == "nls") {
    scal = coef(fit)["scal"]
    r = 1/scal
  }
  
  r1_list$location = c(r1_list$location, loc)
  r1_list$r = c(r1_list$r, r)
  r1_list$fit = c(r1_list$fit, list(fit))
  
  vri <- estimate_vri(covid_clean, r)
  
  
  temp <- data.frame(location = loc, vri_f = vri)


  temp_data <- rbind(temp_data, temp)
}


## Measuring model fitness, residual standard error (RSE).
for (i in seq_len(length(r1_list$fit))) {
  r1_list$rse[[i]] = sigma(r1_list$fit[[i]])
}


## Country using linear model 
unwanted_loc <- r1_list$location[names(r1_list$r) == "t_days"]
temp_data <- temp_data %>% filter (!(location %in% unwanted_loc))

vri_data <- merge(vri_data, temp_data, by = "location")
```

```{r}
temp_data <- NULL
for (loc in vri_data$location) {
  temp <- data.frame(location = vri_data$location[vri_data$location == loc], 
                     vri4 = vri_data$vri4[vri_data$location == loc], 
                     vri8 = vri_data$vri8[vri_data$location == loc], 
                     vrif = vri_data$vri_f[vri_data$location == loc], 
                     aged_65_older = covid[covid$location == loc, ]$aged_65_older[1],
                      gdp_per_capita = covid[covid$location == loc, ]$gdp_per_capita[1],
                      cardiovasc_death_rate = covid[covid$location == loc, ]$cardiovasc_death_rate[1],
                      population_density = covid[covid$location == loc, ]$population_density[1],
                      hospital_beds_per_thousand = covid[covid$location == loc,]$hospital_beds_per_thousand[1],
                      human_development_index = covid[covid$location == loc, ]$human_development_index[1],
                      extreme_poverty = covid[covid$location == loc, ]$extreme_poverty[1],
                      diabetes_prevalence = covid[covid$location == loc, ]$diabetes_prevalence[1],
                      life_expectancy = covid[covid$location == loc, ]$life_expectancy[1],
                      iso_code = covid[covid$location == loc, ]$iso_code[1])
  temp_data <- rbind(temp_data, temp)
}

vri_data <- temp_data
```




```{r}
corruption <- read_xlsx("data/CPI2020_GlobalTablesTS_210125.xlsx", sheet=1,skip=2)
corruption <- corruption %>% select (c("ISO3", "CPI score 2020")) 
#corruption

happiness <- read_csv("data/happiness-cantril-ladder.csv")
happiness <- happiness %>% group_by(Code) %>%
  arrange(Year) %>%
  filter(!is.na(`Life satisfaction in Cantril Ladder (World Happiness Report 2021)`)) %>%
  dplyr::summarise(satisfaction=last(`Life satisfaction in Cantril Ladder (World Happiness Report 2021)`)) 


joint_data <- merge(vri_data, corruption,  by.x=c("iso_code"), by.y=c("ISO3"))

joint_data <- merge(joint_data,happiness, by.x=c("iso_code"), by.y=c("Code"))

# GHE-INDEX
ghs <- read_csv("data/2021-GHS-Index-April-2022.csv")
ghs <- ghs %>% filter(Year == 2021) %>% select(Country,`OVERALL SCORE`)

joint_data <- merge(joint_data, ghs,  by.x=c("location"), by.y=c("Country"))
colnames(joint_data)[17] <- "GHS_score"
joint_data
```

```{r}
# Basic scatter plot
df <- joint_data %>% filter(!is.na(population_density) # set a threshold to remove outliers:
                                    &!is.na(gdp_per_capita) &!is.na(aged_65_older)&
                                      !is.na(extreme_poverty)&
                                      !is.na(human_development_index)& 
                                      !is.na(cardiovasc_death_rate)& 
                                      !is.na(diabetes_prevalence)&
                                      !is.na(hospital_beds_per_thousand)) %>% 
                                      
                            select(c(location,
                                     vri4,
                                     vri8,
                                     vrif,
                                     population_density,
                                     gdp_per_capita,aged_65_older,
                                     `CPI score 2020`,  
                                     satisfaction,
                                     extreme_poverty,
                                     human_development_index,
                                     life_expectancy,
                                      cardiovasc_death_rate,
                                     diabetes_prevalence,
                                      hospital_beds_per_thousand, 
                                     GHS_score))    

df
```


```{r}
library(sigmoid)
zscore <- function(x) {
  # x is a variable (col) in a dataframe
  zscore = (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
  return(zscore)
}

min_max_norm <- function(x) {
    (x - min(x)) / (max(x) - min(x))
}

df <- df %>% filter(vri < 0.01)
#df
scaled_data <- data.frame(vri4 = df$vri4, vri8 = df$vri8, vrif = df$vrif, lapply(df %>% select(-location, -vri4, -vri8, -vrif), min_max_norm))
# UNSURE RN
scaled_data$vri4 <- sigmoid(zscore(scaled_data$vri4))
scaled_data$vri8 <- sigmoid(zscore(scaled_data$vri8))
scaled_data$vrif <- sigmoid(zscore(scaled_data$vrif))
```


```{r warning=FALSE}
# hyper parameter grid search (definitely need a bit modify)
set.seed(1)
mtry <-  seq(2, 12, by = 1)
num_trees <- c(100,150,200,250,300,350,400,450,500)


# Manual Search
#control <- trainControl(method="cv", number=3, search="grid")
grid_param <- expand.grid(.mtry=mtry)
modellist <- list()
for (ntree in num_trees) {
	fit <- train( vri4~., 
                      data= scaled_data %>% select(-vri8, -vrif), 
                      method='rf', 
                      tuneGrid=grid_param, 
	                    ntree= ntree,
                      trControl=trainControl(method='cv', 
                        number=3) )
	key <- toString(ntree)
	modellist[[key]] <- fit$finalModel

}


## COMPARE RESULTS

#lowest_mse <- 1
#model_mse <- modellist[[1]]
highest_r2 <- 0
model_r2 <- modellist[[1]]
for (i in c(1:length(modellist))) {

  result <- predict(modellist[[i]], newdata=scaled_data%>% select(-vri4, -vri8, -vrif))
  result_avg <- mean(scaled_data$vri4)
  r2 = 1 - (sum((scaled_data$vri4 - result)^2))/(sum((scaled_data$vri4 - result_avg)^2))
  if (highest_r2 < r2){
     highest_r2 = r2
     model_r2 = modellist[[i]]
  }
  # mse = min(modellist[[i]]$mse)
  # if (lowest_mse > mse){
  #   lowest_rmse = mse
  #   model_mse = modellist[[i]]
  # }
 
}
#model_mse
model_r2 
highest_r2

```
```{r warning=FALSE}
# hyper parameter grid search (definitely need a bit modify)
set.seed(1)
mtry <-  seq(2, 12, by = 1)
num_trees <- c(100,150,200,250,300,350,400,450,500)


# Manual Search
#control <- trainControl(method="cv", number=3, search="grid")
grid_param <- expand.grid(.mtry=mtry)
modellist <- list()
for (ntree in num_trees) {
	fit <- train( vri8~., 
                      data= scaled_data %>% select(-vri4, -vrif), 
                      method='rf', 
                      tuneGrid=grid_param, 
	                    ntree= ntree,
                      trControl=trainControl(method='cv', 
                        number=3) )
	key <- toString(ntree)
	modellist[[key]] <- fit$finalModel

}


## COMPARE RESULTS

#lowest_mse <- 1
#model_mse <- modellist[[1]]
highest_r2 <- 0
model_r2 <- modellist[[1]]
for (i in c(1:length(modellist))) {

  result <- predict(modellist[[i]], newdata=scaled_data%>% select(-vri4, -vri8, -vrif))
  result_avg <- mean(scaled_data$vri8)
  r2 = 1 - (sum((scaled_data$vri8 - result)^2))/(sum((scaled_data$vri8 - result_avg)^2))
  if (highest_r2 < r2){
     highest_r2 = r2
     model_r2 = modellist[[i]]
  }
  # mse = min(modellist[[i]]$mse)
  # if (lowest_mse > mse){
  #   lowest_rmse = mse
  #   model_mse = modellist[[i]]
  # }
 
}
#model_mse
model_r2 
highest_r2

```


```{r warning=FALSE}
# hyper parameter grid search (definitely need a bit modify)
set.seed(1)
mtry <-  seq(2, 12, by = 1)
num_trees <- c(100,150,200,250,300,350,400,450,500)


# Manual Search
#control <- trainControl(method="cv", number=3, search="grid")
grid_param <- expand.grid(.mtry=mtry)
modellist <- list()
for (ntree in num_trees) {
	fit <- train( vrif~., 
                      data= scaled_data %>% select(-vri8, -vri4), 
                      method='rf', 
                      tuneGrid=grid_param, 
	                    ntree= ntree,
                      trControl=trainControl(method='cv', 
                        number=3) )
	key <- toString(ntree)
	modellist[[key]] <- fit$finalModel

}


## COMPARE RESULTS

#lowest_mse <- 1
#model_mse <- modellist[[1]]
highest_r2 <- 0
model_r2 <- modellist[[1]]
for (i in c(1:length(modellist))) {

  result <- predict(modellist[[i]], newdata=scaled_data%>% select(-vri4, -vri8, -vrif))
  result_avg <- mean(scaled_data$vrif)
  r2 = 1 - (sum((scaled_data$vrif - result)^2))/(sum((scaled_data$vrif - result_avg)^2))
  if (highest_r2 < r2){
     highest_r2 = r2
     model_r2 = modellist[[i]]
  }
  # mse = min(modellist[[i]]$mse)
  # if (lowest_mse > mse){
  #   lowest_rmse = mse
  #   model_mse = modellist[[i]]
  # }
 
}
#model_mse
model_r2 
highest_r2

```

```{r}
high4 <- quantile(scaled_data$vri4)[4]

high8 <- quantile(scaled_data$vri8)[4]

highf <- quantile(scaled_data$vrif)[4]

```


```{r}
scaled_data$label4 <- ifelse(scaled_data$vri4 < high4 , 0, 1)

scaled_data$label8 <- ifelse(scaled_data$vri8 < high8 , 0, 1)

scaled_data$labelf <- ifelse(scaled_data$vrif < highf , 0, 1)
```


```{r}
set.seed(3888)

X = scaled_data %>% select(-vri4, -label4, -vri8, -label8, -vrif, -labelf)
y4 = scaled_data$label4
y8 = scaled_data$label8
yf = scaled_data$labelf

cvK <- 5  # number of CV folds
cv_acc5_50times_svm4 = cv_acc5_svm4 = cv_acc5_50times_rf4 = cv_acc5_rf4 = c()
cv_acc5_50times_svm8 = cv_acc5_svm8 = cv_acc5_50times_rf8 = cv_acc5_rf8 = c()
cv_acc5_50times_svmf = cv_acc5_svmf = cv_acc5_50times_rff = cv_acc5_rff = c()

n_sim = 50 ## number of repeats
for (i in 1:n_sim) {

  cvSets <- cvTools::cvFolds(nrow(X), cvK)  # permute all the data, into 5 folds
  cv_svm <- c()
  
  for (j in 1:cvK) {
    test_id = cvSets$subsets[cvSets$which == j]
    X_test = X[test_id, ]
    X_train = X[-test_id, ]
    y4_test = y4[test_id]
    y4_train = y4[-test_id]
    y8_test = y8[test_id]
    y8_train = y8[-test_id]
    yf_test = yf[test_id]
    yf_train = yf[-test_id]
    
    ## SVM
    svm_res4 <- e1071::svm(x = X_train, y = as.factor(y4_train))
    fit4 <- predict(svm_res4, X_test)
    
    svm_res8 <- e1071::svm(x = X_train, y = as.factor(y8_train))
    fit8 <- predict(svm_res8, X_test)
    
    svm_resf <- e1071::svm(x = X_train, y = as.factor(yf_train))
    fitf <- predict(svm_resf, X_test)
    
    cv_acc5_svm4[j] = mean(fit4 == y4_test)
    cv_acc5_svm8[j] = mean(fit8 == y8_test)
    cv_acc5_svmf[j] = mean(fitf == yf_test)
    
    ## RF
    # rf <- randomForest(x = X_train, y = as.factor(y_train))
    # rf <- predict(rf, X_test)
    # 
    # cv_acc5_rf4[j] = mean(rf == y4_test)
    # cv_acc5_rf8[j] = mean(rf == y8_test)
    # cv_acc5_rff[j] = mean(rf == yf_test)
  }
  
  cv_acc5_50times_svm4 <- append(cv_acc5_50times_svm4, mean(cv_acc5_svm4))
  cv_acc5_50times_svm8 <- append(cv_acc5_50times_svm8, mean(cv_acc5_svm8))
  cv_acc5_50times_svmf <- append(cv_acc5_50times_svmf, mean(cv_acc5_svmf))
  
  # cv_acc5_50times_rf4 <- append(cv_acc5_50times_rf4, mean(cv_acc5_rf4))
  # cv_acc5_50times_rf8 <- append(cv_acc5_50times_rf8, mean(cv_acc5_rf8))
  # cv_acc5_50times_rff <- append(cv_acc5_50times_rff, mean(cv_acc5_rff))
} ## end for

boxplot(cv_acc5_50times_svm4)
boxplot(cv_acc5_50times_svm8)
boxplot(cv_acc5_50times_svmf)
# boxplot(cv_acc5_50times_rf4)
# boxplot(cv_acc5_50times_rf8)
# boxplot(cv_acc5_50times_rff)
```








